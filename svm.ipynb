{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c238ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.svm import SVC # Import SVC for Support Vector Classifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score, roc_curve, auc\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "\n",
    "# Debugging function to check shape alignment\n",
    "def debug_shape(df, name=\"DataFrame\"):\n",
    "    print(f\"{name} shape: {df.shape}\")\n",
    "\n",
    "# Function to safely load CSV files\n",
    "def safe_load_csv(filepath):\n",
    "    try:\n",
    "        return pd.read_csv(filepath, delimiter=';', encoding='utf-8')\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error loading {filepath}. Attempting to skip problematic rows...\")\n",
    "        return pd.read_csv(filepath, on_bad_lines='skip', delimiter=';', encoding='utf-8')\n",
    "\n",
    "# Load data\n",
    "normal = safe_load_csv(\"/Users/bodapati/Desktop/Eoc project/ICS Dataset for Smart Grid Anomaly Detection/ics-dataset-for-smart-grids/but-iec104-i/normal-traffic.csv\")\n",
    "connection_loss = safe_load_csv(\"/Users/bodapati/Desktop/Eoc project/ICS Dataset for Smart Grid Anomaly Detection/ics-dataset-for-smart-grids/but-iec104-i/connection-loss.csv\")\n",
    "switching_attack = safe_load_csv(\"/Users/bodapati/Desktop/Eoc project/ICS Dataset for Smart Grid Anomaly Detection/ics-dataset-for-smart-grids/but-iec104-i/switching-attack.csv\")\n",
    "scanning_attack = safe_load_csv(\"/Users/bodapati/Desktop/Eoc project/ICS Dataset for Smart Grid Anomaly Detection/ics-dataset-for-smart-grids/but-iec104-i/scanning-attack.csv\")\n",
    "dos_attack = safe_load_csv(\"/Users/bodapati/Desktop/Eoc project/ICS Dataset for Smart Grid Anomaly Detection/ics-dataset-for-smart-grids/but-iec104-i/dos-attack.csv\")\n",
    "rogue_devices = safe_load_csv(\"/Users/bodapati/Desktop/Eoc project/ICS Dataset for Smart Grid Anomaly Detection/ics-dataset-for-smart-grids/but-iec104-i/rogue-device.csv\")\n",
    "injection_attack = safe_load_csv(\"/Users/bodapati/Desktop/Eoc project/ICS Dataset for Smart Grid Anomaly Detection/ics-dataset-for-smart-grids/but-iec104-i/injection-attack.csv\")\n",
    "\n",
    "# 2. Assign labels\n",
    "normal['label'] = 0\n",
    "for df in [connection_loss, switching_attack, scanning_attack, dos_attack, rogue_devices, injection_attack]:\n",
    "    df['label'] = 1\n",
    "\n",
    "# Combine all data\n",
    "data = pd.concat([normal, connection_loss, switching_attack, scanning_attack, dos_attack, rogue_devices, injection_attack], ignore_index=True)\n",
    "debug_shape(data, \"Combined Data\")\n",
    "\n",
    "# Check for mixed or improperly parsed columns and clean\n",
    "def clean_data_columns(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "data = clean_data_columns(data)\n",
    "\n",
    "# 3. Apply a stronger transformation to normal data\n",
    "def transform_normal_data(data, noise_level=0.5):\n",
    "    noise = np.random.normal(0, noise_level, data.shape)\n",
    "    scaled_data = data * np.random.uniform(0.5, 1.5, data.shape)\n",
    "    transformed_data = scaled_data + noise\n",
    "    return transformed_data\n",
    "\n",
    "normal_features = data[data['label'] == 0].drop(columns=['label'])\n",
    "debug_shape(normal_features, \"Normal Features Before Transformation\")\n",
    "\n",
    "# Apply transformation to normal data\n",
    "transformed_normal_features = transform_normal_data(normal_features.to_numpy(), noise_level=0.5)\n",
    "transformed_normal = pd.DataFrame(transformed_normal_features, columns=normal_features.columns)\n",
    "transformed_normal['label'] = 0\n",
    "debug_shape(transformed_normal, \"Transformed Normal Data\")\n",
    "\n",
    "# Plot original and transformed normal data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(normal_features.corr(), cmap='coolwarm', annot=False)\n",
    "plt.title('A.) Original Normal Data Correlation', fontsize=18)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(pd.DataFrame(transformed_normal_features, columns=normal_features.columns).corr(), cmap='coolwarm', annot=False)\n",
    "plt.title('B.) Transformed Normal Data Correlation', fontsize=18)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Combine transformed normal data back with other classes\n",
    "other_classes = data[data['label'] != 0]\n",
    "data_transformed = pd.concat([transformed_normal, other_classes], ignore_index=True)\n",
    "debug_shape(data_transformed, \"Data Transformed After Transformation\")\n",
    "\n",
    "# Ensure consistency in data cleaning\n",
    "data_transformed = clean_data_columns(data_transformed)\n",
    "\n",
    "# 4. Handle missing values\n",
    "non_nan_columns = data_transformed.columns[data_transformed.notna().any()].tolist()\n",
    "data_transformed = data_transformed[non_nan_columns]\n",
    "debug_shape(data_transformed, \"Data Transformed After Dropping NaN Columns\")\n",
    "\n",
    "# Separate features and labels\n",
    "features_transformed = data_transformed.drop(columns=['label'])\n",
    "label_transformed = data_transformed['label']\n",
    "debug_shape(features_transformed, \"Features Transformed\")\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "features_cleaned = imputer.fit_transform(features_transformed)\n",
    "\n",
    "# Ensure column alignment\n",
    "features_cleaned_df = pd.DataFrame(features_cleaned, columns=features_transformed.columns)\n",
    "features_cleaned_df['label'] = label_transformed.reset_index(drop=True)\n",
    "debug_shape(features_cleaned_df, \"Features Cleaned\")\n",
    "\n",
    "# 5. Feature selection and preprocessing\n",
    "# Scaling is crucial for SVM\n",
    "scaler = StandardScaler()\n",
    "numerical_features = [col for col in features_cleaned_df.columns if col != 'label']\n",
    "features_cleaned_df[numerical_features] = scaler.fit_transform(features_cleaned_df[numerical_features])\n",
    "features_cleaned_df['label'] = features_cleaned_df['label'].astype(int)\n",
    "\n",
    "# Ensure no NaN or inf values in normal_features and transformed_normal_features\n",
    "normal_features_clean = np.nan_to_num(normal_features.to_numpy(), nan=0.0, posinf=0.0, neginf=0.0)\n",
    "transformed_normal_features_clean = np.nan_to_num(transformed_normal_features, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "euclidean_distances = [euclidean(original, transformed) \n",
    "                       for original, transformed in zip(normal_features_clean, transformed_normal_features_clean)]\n",
    "\n",
    "euclidean_mean = np.mean(euclidean_distances)\n",
    "euclidean_std = np.std(euclidean_distances)\n",
    "\n",
    "print(f\"Euclidean Distance: Mean = {euclidean_mean}, Std Dev = {euclidean_std}\")\n",
    "\n",
    "# Plot Euclidean Distance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(euclidean_distances, kde=True, bins=50, color='green', label='Euclidean Distance')\n",
    "plt.title('Euclidean Distance Before and After Transformation', fontsize=16)\n",
    "plt.xlabel('Euclidean Distance', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 6. Split data\n",
    "X = features_cleaned_df.drop(columns=['label'])\n",
    "y = features_cleaned_df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "debug_shape(X_train, \"X_train\")\n",
    "debug_shape(X_test, \"X_test\")\n",
    "\n",
    "# 7. Handle imbalance using SMOTE\n",
    "smote = SMOTE(sampling_strategy={0: int(y_train.value_counts()[1] * 0.8)}, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "debug_shape(X_train_resampled, \"X_train_resampled\")\n",
    "\n",
    "# 8. Perform 5-fold cross-validation with SVM\n",
    "# For SVM, you might want to tune hyperparameters. For simplicity, we'll start with default.\n",
    "# A small C value (regularization) and 'rbf' kernel are common starting points.\n",
    "# If performance is poor, consider GridSearchCV for C and gamma.\n",
    "svm_clf = SVC(random_state=42, probability=True) # probability=True is needed for roc_curve\n",
    "cv_scores = cross_val_score(svm_clf, X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "print(f\"5-Fold Cross-Validation Accuracy (SVM): Mean = {cv_scores.mean():.2f}, Std Dev = {cv_scores.std():.2f}\")\n",
    "\n",
    "# Plot cross-validation scores\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(range(1, 6), cv_scores, color='skyblue', edgecolor='black')\n",
    "plt.title('5-Fold Cross-Validation Accuracy Scores (SVM)', fontsize=16)\n",
    "plt.xlabel('Fold', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.xticks(range(1, 6), fontsize=12)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# 9. Train classifier on full resampled training data\n",
    "svm_clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 10. Calculate and print train and test accuracy\n",
    "y_train_pred = svm_clf.predict(X_train_resampled)\n",
    "train_accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
    "y_test_pred = svm_clf.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Accuracy (SVM): {train_accuracy:.2f}\")\n",
    "print(f\"Test Accuracy (SVM): {test_accuracy:.2f}\")\n",
    "\n",
    "# 11. Evaluate the model\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "# Generate ROC Curve\n",
    "y_pred_prob = svm_clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Confusion Matrix Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Attack'], yticklabels=['Normal', 'Attack'])\n",
    "plt.title('Confusion Matrix (SVM)', fontsize=16)\n",
    "plt.xlabel('Predicted', fontsize=14)\n",
    "plt.ylabel('True', fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Metrics Plot\n",
    "metrics_df = pd.DataFrame(report).transpose().iloc[:-1, :3]\n",
    "metrics_df.plot(kind='bar', figsize=(12, 6), color=['blue', 'green', 'red'])\n",
    "plt.title('Classification Metrics (SVM)', fontsize=16)\n",
    "plt.xlabel('Metrics', fontsize=14)\n",
    "plt.ylabel('Score', fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve (SVM)', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
